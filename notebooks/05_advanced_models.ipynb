{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Advanced Multi-Horizon (Optimized) for ADA ===\n",
      "ADA - Close_t+1: Train=2097, Test=525\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:28:05] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:28:05] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=0.025, MAE=0.017\n",
      "   XGB=> RMSE=0.028, MAE=0.019\n",
      "     Top RF feats: [('Close', np.float64(0.993042887237243)), ('MACD_Signal', np.float64(0.0032221491006848868)), ('MACD', np.float64(0.0014656258874830874))]\n",
      "     Top XGB feats: [('MA_20', np.float32(0.5321405)), ('Close', np.float32(0.2857514)), ('BB_upper', np.float32(0.1637891))]\n",
      "\n",
      "ADA - Close_t+7: Train=2097, Test=525\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:28:11] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:28:11] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=0.070, MAE=0.049\n",
      "   XGB=> RMSE=0.076, MAE=0.052\n",
      "     Top RF feats: [('Close', np.float64(0.9542975897188065)), ('MA_20', np.float64(0.010030532708462757)), ('BB_lower', np.float64(0.009370173455672565))]\n",
      "     Top XGB feats: [('Close', np.float32(0.50623214)), ('MA_20', np.float32(0.34994417)), ('BB_upper', np.float32(0.09543677))]\n",
      "\n",
      "ADA - Close_t+30: Train=2097, Test=525\n",
      "   [RF best params] {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:28:18] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:28:18] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 1.0, 'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=0.199, MAE=0.128\n",
      "   XGB=> RMSE=0.204, MAE=0.126\n",
      "     Top RF feats: [('Close', np.float64(0.5708903535069013)), ('MA_20', np.float64(0.2266440319562162)), ('BB_upper', np.float64(0.09752810845801899))]\n",
      "     Top XGB feats: [('Close', np.float32(0.4055349)), ('MA_20', np.float32(0.36321267)), ('BB_upper', np.float32(0.06664781))]\n",
      "\n",
      "ADA - Close_t+90: Train=2097, Test=525\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:28:28] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:28:28] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 1.0, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=0.324, MAE=0.218\n",
      "   XGB=> RMSE=0.316, MAE=0.209\n",
      "     Top RF feats: [('Close', np.float64(0.3135462240951888)), ('BB_upper', np.float64(0.30423933419108146)), ('MA_20', np.float64(0.18102385145315208))]\n",
      "     Top XGB feats: [('Close', np.float32(0.33769667)), ('BB_upper', np.float32(0.29415932)), ('MA_20', np.float32(0.1318298))]\n",
      "\n",
      "\n",
      "=== Advanced Multi-Horizon (Optimized) for AVAX ===\n",
      "AVAX - Close_t+1: Train=1228, Test=307\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:28:31] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:28:31] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 1.0, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=2.338, MAE=1.626\n",
      "   XGB=> RMSE=2.634, MAE=1.841\n",
      "     Top RF feats: [('Close', np.float64(0.9928097824265532)), ('BB_upper', np.float64(0.0026684886755679394)), ('MA_20', np.float64(0.001086585872003693))]\n",
      "     Top XGB feats: [('MA_20', np.float32(0.60730636)), ('Close', np.float32(0.29590973)), ('BB_upper', np.float32(0.072190575))]\n",
      "\n",
      "AVAX - Close_t+7: Train=1228, Test=307\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:28:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:28:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=6.405, MAE=4.671\n",
      "   XGB=> RMSE=6.517, MAE=4.870\n",
      "     Top RF feats: [('Close', np.float64(0.9455239143227508)), ('MA_20', np.float64(0.01224471032619345)), ('BB_upper', np.float64(0.008944983294802235))]\n",
      "     Top XGB feats: [('Close', np.float32(0.45533383)), ('MA_20', np.float32(0.35109973)), ('BB_upper', np.float32(0.05443607))]\n",
      "\n",
      "AVAX - Close_t+30: Train=1228, Test=307\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:28:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:28:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=13.767, MAE=10.298\n",
      "   XGB=> RMSE=13.148, MAE=9.960\n",
      "     Top RF feats: [('Close', np.float64(0.7839274370921672)), ('MACD', np.float64(0.050594504570749294)), ('MACD_Signal', np.float64(0.03609591723901577))]\n",
      "     Top XGB feats: [('Close', np.float32(0.49376622)), ('BB_lower', np.float32(0.19736347)), ('MACD', np.float32(0.06347872))]\n",
      "\n",
      "AVAX - Close_t+90: Train=1228, Test=307\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:28:42] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:28:42] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 1.0, 'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=25.242, MAE=22.064\n",
      "   XGB=> RMSE=26.568, MAE=21.474\n",
      "     Top RF feats: [('Close', np.float64(0.34655865534113545)), ('BB_lower', np.float64(0.19760346875229656)), ('MACD_Signal', np.float64(0.18647316469725622))]\n",
      "     Top XGB feats: [('Close', np.float32(0.307904)), ('MACD_Signal', np.float32(0.16972944)), ('BB_upper', np.float32(0.13606173))]\n",
      "\n",
      "\n",
      "=== Advanced Multi-Horizon (Optimized) for BCH ===\n",
      "BCH - Close_t+1: Train=2153, Test=539\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:28:48] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:28:48] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=19.518, MAE=12.755\n",
      "   XGB=> RMSE=19.133, MAE=12.331\n",
      "     Top RF feats: [('Close', np.float64(0.9907342811437372)), ('MACD_Hist', np.float64(0.002114065852051984)), ('MACD_Signal', np.float64(0.0015000245235323318))]\n",
      "     Top XGB feats: [('BB_upper', np.float32(0.47570053)), ('Close', np.float32(0.30702278)), ('MA_20', np.float32(0.14579782))]\n",
      "\n",
      "BCH - Close_t+7: Train=2153, Test=539\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:28:54] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:28:54] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=49.221, MAE=35.099\n",
      "   XGB=> RMSE=49.545, MAE=32.603\n",
      "     Top RF feats: [('Close', np.float64(0.935648996986692)), ('BB_lower', np.float64(0.014990139982333525)), ('MACD', np.float64(0.014844323755859038))]\n",
      "     Top XGB feats: [('Close', np.float32(0.38532338)), ('BB_upper', np.float32(0.35971665)), ('MA_20', np.float32(0.099297926))]\n",
      "\n",
      "BCH - Close_t+30: Train=2153, Test=539\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:29:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:29:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=101.695, MAE=73.490\n",
      "   XGB=> RMSE=86.247, MAE=60.786\n",
      "     Top RF feats: [('BB_upper', np.float64(0.3960023024465909)), ('Close', np.float64(0.2858005352846891)), ('MACD_Signal', np.float64(0.14161365758232491))]\n",
      "     Top XGB feats: [('BB_upper', np.float32(0.45244578)), ('Close', np.float32(0.14585668)), ('MACD_Signal', np.float32(0.11549029))]\n",
      "\n",
      "BCH - Close_t+90: Train=2153, Test=539\n",
      "   [RF best params] {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:29:06] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:29:06] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 1.0, 'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=262.559, MAE=180.405\n",
      "   XGB=> RMSE=243.644, MAE=163.855\n",
      "     Top RF feats: [('BB_upper', np.float64(0.3068294409703083)), ('MACD_Signal', np.float64(0.16693816422690033)), ('BB_lower', np.float64(0.11305889229781566))]\n",
      "     Top XGB feats: [('BB_upper', np.float32(0.29930443)), ('MACD_Signal', np.float32(0.13913795)), ('MACD', np.float32(0.10827436))]\n",
      "\n",
      "\n",
      "=== Advanced Multi-Horizon (Optimized) for BNB ===\n",
      "BNB - Close_t+1: Train=2152, Test=538\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:29:12] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:29:12] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 1.0, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=28.022, MAE=17.769\n",
      "   XGB=> RMSE=36.484, MAE=23.103\n",
      "     Top RF feats: [('Close', np.float64(0.42780128620819363)), ('BB_upper', np.float64(0.31097370499954125)), ('MA_20', np.float64(0.2595912086955943))]\n",
      "     Top XGB feats: [('BB_upper', np.float32(0.6002729)), ('Close', np.float32(0.24967998)), ('MA_20', np.float32(0.13322338))]\n",
      "\n",
      "BNB - Close_t+7: Train=2152, Test=538\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:29:18] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:29:18] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=96.994, MAE=60.003\n",
      "   XGB=> RMSE=65.990, MAE=46.168\n",
      "     Top RF feats: [('BB_upper', np.float64(0.4145935126674822)), ('MA_20', np.float64(0.3266722923727388)), ('Close', np.float64(0.25046470040426533))]\n",
      "     Top XGB feats: [('MA_20', np.float32(0.6548459)), ('BB_upper', np.float32(0.19400191)), ('Close', np.float32(0.104846634))]\n",
      "\n",
      "BNB - Close_t+30: Train=2152, Test=538\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:29:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:29:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=121.536, MAE=100.740\n",
      "   XGB=> RMSE=116.616, MAE=98.340\n",
      "     Top RF feats: [('MA_20', np.float64(0.8625405771206849)), ('Close', np.float64(0.0582627419898549)), ('MACD_Signal', np.float64(0.0182844916719445))]\n",
      "     Top XGB feats: [('MA_20', np.float32(0.5468298)), ('BB_upper', np.float32(0.23726717)), ('BB_lower', np.float32(0.08648091))]\n",
      "\n",
      "BNB - Close_t+90: Train=2152, Test=538\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:29:33] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:29:33] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=199.940, MAE=174.567\n",
      "   XGB=> RMSE=198.964, MAE=174.262\n",
      "     Top RF feats: [('Close', np.float64(0.5827520806298361)), ('BB_upper', np.float64(0.33837761381276255)), ('BB_lower', np.float64(0.023407019484440874))]\n",
      "     Top XGB feats: [('BB_upper', np.float32(0.7112286)), ('Close', np.float32(0.13203415)), ('MA_20', np.float32(0.04209777))]\n",
      "\n",
      "\n",
      "=== Advanced Multi-Horizon (Optimized) for BTC ===\n",
      "BTC - Close_t+1: Train=4207, Test=1052\n",
      "   [RF best params] {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:29:46] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:29:46] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 1.0, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=7386.967, MAE=3532.142\n",
      "   XGB=> RMSE=7557.049, MAE=3700.352\n",
      "     Top RF feats: [('Close', np.float64(0.4935439450236302)), ('BB_upper', np.float64(0.3471308024337093)), ('MA_20', np.float64(0.1564122625198403))]\n",
      "     Top XGB feats: [('MA_20', np.float32(0.65213853)), ('Close', np.float32(0.15545653)), ('BB_upper', np.float32(0.14102428))]\n",
      "\n",
      "BTC - Close_t+7: Train=4207, Test=1052\n",
      "   [RF best params] {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:30:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:30:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 1.0, 'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=11818.635, MAE=8935.651\n",
      "   XGB=> RMSE=10770.626, MAE=7778.204\n",
      "     Top RF feats: [('BB_upper', np.float64(0.3411005874715445)), ('Close', np.float64(0.32606394462421173)), ('MA_20', np.float64(0.3231704820268061))]\n",
      "     Top XGB feats: [('MA_20', np.float32(0.6530132)), ('Close', np.float32(0.2689695)), ('BB_upper', np.float32(0.04004634))]\n",
      "\n",
      "BTC - Close_t+30: Train=4207, Test=1052\n",
      "   [RF best params] {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:30:13] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:30:13] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=18585.163, MAE=15604.171\n",
      "   XGB=> RMSE=19051.825, MAE=15744.288\n",
      "     Top RF feats: [('BB_lower', np.float64(0.5735211838270055)), ('MA_20', np.float64(0.35704045389360267)), ('Close', np.float64(0.03819380894688284))]\n",
      "     Top XGB feats: [('BB_lower', np.float32(0.6300586)), ('MA_20', np.float32(0.20992494)), ('Close', np.float32(0.12347813))]\n",
      "\n",
      "BTC - Close_t+90: Train=4207, Test=1052\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:30:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:30:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 1.0, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=31147.445, MAE=28158.080\n",
      "   XGB=> RMSE=31081.837, MAE=28051.561\n",
      "     Top RF feats: [('BB_lower', np.float64(0.7219545181010856)), ('Close', np.float64(0.18880124684271626)), ('BB_upper', np.float64(0.047291289530010265))]\n",
      "     Top XGB feats: [('BB_lower', np.float32(0.51735276)), ('Close', np.float32(0.32258365)), ('MA_20', np.float32(0.053470902))]\n",
      "\n",
      "\n",
      "=== Advanced Multi-Horizon (Optimized) for DOGE ===\n",
      "DOGE - Close_t+1: Train=3206, Test=802\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:30:42] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:30:42] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 1.0, 'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=0.018, MAE=0.009\n",
      "   XGB=> RMSE=0.017, MAE=0.010\n",
      "     Top RF feats: [('Close', np.float64(0.9416126972091753)), ('BB_upper', np.float64(0.021649604999322558)), ('MACD_Signal', np.float64(0.01507912703155087))]\n",
      "     Top XGB feats: [('BB_upper', np.float32(0.5937013)), ('Close', np.float32(0.37854156)), ('Stoch_%D', np.float32(0.010488584))]\n",
      "\n",
      "DOGE - Close_t+7: Train=3206, Test=802\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:30:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:30:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=0.042, MAE=0.025\n",
      "   XGB=> RMSE=0.036, MAE=0.022\n",
      "     Top RF feats: [('Close', np.float64(0.8550860119202652)), ('BB_upper', np.float64(0.08552377720377578)), ('BB_lower', np.float64(0.015028885048650072))]\n",
      "     Top XGB feats: [('Close', np.float32(0.5139862)), ('BB_upper', np.float32(0.3637014)), ('MA_20', np.float32(0.061648067))]\n",
      "\n",
      "DOGE - Close_t+30: Train=3206, Test=802\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:31:13] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:31:13] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 1.0, 'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=0.080, MAE=0.049\n",
      "   XGB=> RMSE=0.076, MAE=0.044\n",
      "     Top RF feats: [('MA_20', np.float64(0.6447154741826091)), ('Close', np.float64(0.14922294260389202)), ('BB_upper', np.float64(0.11685102472642493))]\n",
      "     Top XGB feats: [('MA_20', np.float32(0.3920209)), ('Close', np.float32(0.34128705)), ('BB_upper', np.float32(0.13759238))]\n",
      "\n",
      "DOGE - Close_t+90: Train=3206, Test=802\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:31:29] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:31:29] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=0.107, MAE=0.061\n",
      "   XGB=> RMSE=0.107, MAE=0.062\n",
      "     Top RF feats: [('MA_20', np.float64(0.4981916470880582)), ('Close', np.float64(0.27743816104919927)), ('BB_upper', np.float64(0.07722669760607147))]\n",
      "     Top XGB feats: [('MA_20', np.float32(0.42494094)), ('Close', np.float32(0.3041363)), ('BB_upper', np.float32(0.11057707))]\n",
      "\n",
      "\n",
      "=== Advanced Multi-Horizon (Optimized) for DOT ===\n",
      "DOT - Close_t+1: Train=1254, Test=314\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:31:33] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:31:33] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=0.371, MAE=0.258\n",
      "   XGB=> RMSE=0.484, MAE=0.286\n",
      "     Top RF feats: [('Close', np.float64(0.9977886545387993)), ('MACD_Signal', np.float64(0.0005239243596542614)), ('MACD', np.float64(0.00038491190759055354))]\n",
      "     Top XGB feats: [('Close', np.float32(0.4460629)), ('BB_upper', np.float32(0.2688006)), ('MA_20', np.float32(0.20645675))]\n",
      "\n",
      "DOT - Close_t+7: Train=1254, Test=314\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:31:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:31:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=1.643, MAE=1.010\n",
      "   XGB=> RMSE=1.494, MAE=0.980\n",
      "     Top RF feats: [('Close', np.float64(0.9262003349518813)), ('BB_upper', np.float64(0.038421722136225196)), ('MACD_Signal', np.float64(0.014043260835191196))]\n",
      "     Top XGB feats: [('Close', np.float32(0.4343379)), ('BB_upper', np.float32(0.32247096)), ('MA_20', np.float32(0.14312112))]\n",
      "\n",
      "DOT - Close_t+30: Train=1254, Test=314\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:31:40] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:31:40] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=4.340, MAE=2.249\n",
      "   XGB=> RMSE=4.170, MAE=2.270\n",
      "     Top RF feats: [('Close', np.float64(0.7187010601237892)), ('MACD_Signal', np.float64(0.1119937373241878)), ('MACD', np.float64(0.0738657297126008))]\n",
      "     Top XGB feats: [('Close', np.float32(0.463433)), ('BB_upper', np.float32(0.20582442)), ('MACD_Signal', np.float32(0.13430227))]\n",
      "\n",
      "DOT - Close_t+90: Train=1254, Test=314\n",
      "   [RF best params] {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:31:42] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:31:43] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=9.316, MAE=5.374\n",
      "   XGB=> RMSE=8.662, MAE=4.916\n",
      "     Top RF feats: [('Close', np.float64(0.3336741124082874)), ('BB_upper', np.float64(0.19858952494372287)), ('BB_lower', np.float64(0.18087266428898954))]\n",
      "     Top XGB feats: [('Close', np.float32(0.31433427)), ('BB_upper', np.float32(0.13517655)), ('MACD_Hist', np.float32(0.12028142))]\n",
      "\n",
      "\n",
      "=== Advanced Multi-Horizon (Optimized) for ETH ===\n",
      "ETH - Close_t+1: Train=2726, Test=682\n",
      "   [RF best params] {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:31:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:31:51] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=114.695, MAE=74.893\n",
      "   XGB=> RMSE=109.378, MAE=78.309\n",
      "     Top RF feats: [('Close', np.float64(0.9967319401733618)), ('BB_upper', np.float64(0.0005370023777426144)), ('MACD_Signal', np.float64(0.000506791897282793))]\n",
      "     Top XGB feats: [('MA_20', np.float32(0.5056787)), ('Close', np.float32(0.40382746)), ('BB_upper', np.float32(0.079518504))]\n",
      "\n",
      "ETH - Close_t+7: Train=2726, Test=682\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:31:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:31:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=267.934, MAE=196.371\n",
      "   XGB=> RMSE=298.830, MAE=217.892\n",
      "     Top RF feats: [('Close', np.float64(0.9783309786259595)), ('BB_lower', np.float64(0.0064957745374832265)), ('BB_upper', np.float64(0.005496797009065149))]\n",
      "     Top XGB feats: [('Close', np.float32(0.53573126)), ('MA_20', np.float32(0.37042058)), ('BB_upper', np.float32(0.03813981))]\n",
      "\n",
      "ETH - Close_t+30: Train=2726, Test=682\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:32:06] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:32:06] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 1.0, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=598.915, MAE=502.431\n",
      "   XGB=> RMSE=535.133, MAE=431.782\n",
      "     Top RF feats: [('Close', np.float64(0.7258830110492939)), ('MA_20', np.float64(0.17253874680317552)), ('BB_lower', np.float64(0.06132757007067385))]\n",
      "     Top XGB feats: [('MA_20', np.float32(0.3972449)), ('Close', np.float32(0.3705515)), ('BB_upper', np.float32(0.12839669))]\n",
      "\n",
      "ETH - Close_t+90: Train=2726, Test=682\n",
      "   [RF best params] {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:32:12] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:32:12] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=777.828, MAE=610.738\n",
      "   XGB=> RMSE=701.996, MAE=570.379\n",
      "     Top RF feats: [('Close', np.float64(0.5398100708020828)), ('MA_20', np.float64(0.29595762150105104)), ('BB_lower', np.float64(0.06775487331216375))]\n",
      "     Top XGB feats: [('MA_20', np.float32(0.39105436)), ('Close', np.float32(0.29068726)), ('BB_lower', np.float32(0.14602984))]\n",
      "\n",
      "\n",
      "=== Advanced Multi-Horizon (Optimized) for LEO ===\n",
      "LEO - Close_t+1: Train=1620, Test=405\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:32:18] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:32:18] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=0.962, MAE=0.382\n",
      "   XGB=> RMSE=0.995, MAE=0.421\n",
      "     Top RF feats: [('Close', np.float64(0.9951638535303363)), ('MA_20', np.float64(0.0007209956785364705)), ('MACD_Signal', np.float64(0.0007046562479050237))]\n",
      "     Top XGB feats: [('BB_upper', np.float32(0.60335237)), ('Close', np.float32(0.31508863)), ('MA_20', np.float32(0.04993919))]\n",
      "\n",
      "LEO - Close_t+7: Train=1620, Test=405\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:32:22] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:32:22] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=1.145, MAE=0.586\n",
      "   XGB=> RMSE=1.144, MAE=0.598\n",
      "     Top RF feats: [('Close', np.float64(0.8499213108896405)), ('MA_20', np.float64(0.08687004137698694)), ('BB_upper', np.float64(0.04937851433430069))]\n",
      "     Top XGB feats: [('Close', np.float32(0.5268091)), ('MA_20', np.float32(0.32730693)), ('BB_upper', np.float32(0.08422774))]\n",
      "\n",
      "LEO - Close_t+30: Train=1620, Test=405\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:32:29] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:32:29] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 1.0, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=1.645, MAE=1.188\n",
      "   XGB=> RMSE=1.644, MAE=1.214\n",
      "     Top RF feats: [('BB_lower', np.float64(0.7562570669473588)), ('Close', np.float64(0.15011469758440524)), ('MA_20', np.float64(0.04040179287763927))]\n",
      "     Top XGB feats: [('BB_lower', np.float32(0.4573872)), ('Close', np.float32(0.3334686)), ('MA_20', np.float32(0.11088287))]\n",
      "\n",
      "LEO - Close_t+90: Train=1620, Test=405\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:32:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:32:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=2.586, MAE=2.063\n",
      "   XGB=> RMSE=2.700, MAE=2.207\n",
      "     Top RF feats: [('MA_20', np.float64(0.7204243089055503)), ('BB_upper', np.float64(0.08147900239950315)), ('Close', np.float64(0.07319508461993236))]\n",
      "     Top XGB feats: [('BB_upper', np.float32(0.43490592)), ('MA_20', np.float32(0.29012832)), ('Close', np.float32(0.10432091))]\n",
      "\n",
      "\n",
      "=== Advanced Multi-Horizon (Optimized) for LINK ===\n",
      "LINK - Close_t+1: Train=2105, Test=527\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:32:41] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:32:41] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=0.790, MAE=0.539\n",
      "   XGB=> RMSE=0.918, MAE=0.637\n",
      "     Top RF feats: [('Close', np.float64(0.9280496609219928)), ('MA_20', np.float64(0.06693485003775498)), ('BB_upper', np.float64(0.0028120485662947443))]\n",
      "     Top XGB feats: [('BB_upper', np.float32(0.512966)), ('Close', np.float32(0.35053748)), ('MA_20', np.float32(0.09618296))]\n",
      "\n",
      "LINK - Close_t+7: Train=2105, Test=527\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:32:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:32:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=2.284, MAE=1.672\n",
      "   XGB=> RMSE=2.011, MAE=1.454\n",
      "     Top RF feats: [('Close', np.float64(0.8174850979941233)), ('MA_20', np.float64(0.1073675644218376)), ('BB_upper', np.float64(0.045366555166522604))]\n",
      "     Top XGB feats: [('Close', np.float32(0.4983183)), ('BB_upper', np.float32(0.34518027)), ('MA_20', np.float32(0.095378734))]\n",
      "\n",
      "LINK - Close_t+30: Train=2105, Test=527\n",
      "   [RF best params] {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:32:54] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:32:54] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=4.565, MAE=3.422\n",
      "   XGB=> RMSE=4.522, MAE=3.481\n",
      "     Top RF feats: [('Close', np.float64(0.6398578856840855)), ('MA_20', np.float64(0.14246314213416678)), ('BB_upper', np.float64(0.11605009656241537))]\n",
      "     Top XGB feats: [('Close', np.float32(0.33383235)), ('BB_lower', np.float32(0.25738463)), ('BB_upper', np.float32(0.16595377))]\n",
      "\n",
      "LINK - Close_t+90: Train=2105, Test=527\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:33:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:33:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=8.328, MAE=6.771\n",
      "   XGB=> RMSE=7.059, MAE=5.595\n",
      "     Top RF feats: [('Close', np.float64(0.47383575716742377)), ('BB_lower', np.float64(0.3102889412260985)), ('MACD', np.float64(0.05884395277446839))]\n",
      "     Top XGB feats: [('Close', np.float32(0.3597726)), ('BB_lower', np.float32(0.27838808)), ('MA_20', np.float32(0.098895386))]\n",
      "\n",
      "\n",
      "=== Advanced Multi-Horizon (Optimized) for LTC ===\n",
      "LTC - Close_t+1: Train=3391, Test=848\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:33:10] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:33:10] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 1.0, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=3.514, MAE=2.344\n",
      "   XGB=> RMSE=3.980, MAE=2.961\n",
      "     Top RF feats: [('Close', np.float64(0.9983697831694613)), ('MACD', np.float64(0.0003566986223444732)), ('MACD_Hist', np.float64(0.000265678669571897))]\n",
      "     Top XGB feats: [('BB_upper', np.float32(0.59645545)), ('Close', np.float32(0.30957577)), ('MA_20', np.float32(0.061397288))]\n",
      "\n",
      "LTC - Close_t+7: Train=3391, Test=848\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:33:20] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:33:20] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 1.0, 'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=10.471, MAE=7.458\n",
      "   XGB=> RMSE=10.918, MAE=7.880\n",
      "     Top RF feats: [('Close', np.float64(0.9702841006234812)), ('MA_20', np.float64(0.008227859083514236)), ('BB_lower', np.float64(0.006170925262992107))]\n",
      "     Top XGB feats: [('Close', np.float32(0.55605674)), ('BB_upper', np.float32(0.32105637)), ('MA_20', np.float32(0.032115776))]\n",
      "\n",
      "LTC - Close_t+30: Train=3391, Test=848\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:33:29] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:33:29] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=23.765, MAE=19.518\n",
      "   XGB=> RMSE=27.657, MAE=22.088\n",
      "     Top RF feats: [('Close', np.float64(0.7327352408131583)), ('MA_20', np.float64(0.11453959237528832)), ('BB_upper', np.float64(0.08043449981330272))]\n",
      "     Top XGB feats: [('Close', np.float32(0.4477242)), ('BB_upper', np.float32(0.26181802)), ('MA_20', np.float32(0.089427106))]\n",
      "\n",
      "LTC - Close_t+90: Train=3391, Test=848\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:33:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:33:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=20.440, MAE=16.138\n",
      "   XGB=> RMSE=20.842, MAE=16.278\n",
      "     Top RF feats: [('MA_20', np.float64(0.4967910892210404)), ('Close', np.float64(0.31184004257702036)), ('BB_lower', np.float64(0.05155586438336164))]\n",
      "     Top XGB feats: [('MA_20', np.float32(0.37830245)), ('Close', np.float32(0.32473633)), ('BB_upper', np.float32(0.063035294))]\n",
      "\n",
      "\n",
      "=== Advanced Multi-Horizon (Optimized) for MATIC ===\n",
      "MATIC - Close_t+1: Train=1637, Test=410\n",
      "   [RF best params] {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:33:42] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:33:42] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=0.040, MAE=0.030\n",
      "   XGB=> RMSE=0.035, MAE=0.026\n",
      "     Top RF feats: [('Close', np.float64(0.9394364578082484)), ('MA_20', np.float64(0.038451123755384446)), ('BB_upper', np.float64(0.01816305316027627))]\n",
      "     Top XGB feats: [('BB_upper', np.float32(0.721437)), ('Close', np.float32(0.2114239)), ('MA_20', np.float32(0.051629845))]\n",
      "\n",
      "MATIC - Close_t+7: Train=1637, Test=410\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:33:46] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:33:46] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=0.116, MAE=0.094\n",
      "   XGB=> RMSE=0.108, MAE=0.088\n",
      "     Top RF feats: [('Close', np.float64(0.9035697229359573)), ('MA_20', np.float64(0.038896906617835354)), ('BB_upper', np.float64(0.032320120730404946))]\n",
      "     Top XGB feats: [('Close', np.float32(0.47531363)), ('BB_upper', np.float32(0.39891335)), ('MA_20', np.float32(0.04084244))]\n",
      "\n",
      "MATIC - Close_t+30: Train=1637, Test=410\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:33:51] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:33:51] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=0.331, MAE=0.265\n",
      "   XGB=> RMSE=0.346, MAE=0.264\n",
      "     Top RF feats: [('MA_20', np.float64(0.7686809133805217)), ('Close', np.float64(0.15218356508418834)), ('BB_lower', np.float64(0.037444608035032204))]\n",
      "     Top XGB feats: [('MA_20', np.float32(0.35557434)), ('Close', np.float32(0.28042215)), ('BB_lower', np.float32(0.12183098))]\n",
      "\n",
      "MATIC - Close_t+90: Train=1637, Test=410\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:33:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:33:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=0.384, MAE=0.343\n",
      "   XGB=> RMSE=0.382, MAE=0.336\n",
      "     Top RF feats: [('MA_20', np.float64(0.7735401291566578)), ('BB_upper', np.float64(0.0753828868947586)), ('MACD_Signal', np.float64(0.04413921546429168))]\n",
      "     Top XGB feats: [('MA_20', np.float32(0.3411375)), ('Close', np.float32(0.3286872)), ('BB_upper', np.float32(0.07736443))]\n",
      "\n",
      "\n",
      "=== Advanced Multi-Horizon (Optimized) for NEAR ===\n",
      "NEAR - Close_t+1: Train=1211, Test=303\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:33:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:33:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=0.407, MAE=0.291\n",
      "   XGB=> RMSE=0.370, MAE=0.264\n",
      "     Top RF feats: [('Close', np.float64(0.9962921812906259)), ('MACD', np.float64(0.0008357409258839786)), ('MACD_Signal', np.float64(0.000630453958471788))]\n",
      "     Top XGB feats: [('BB_upper', np.float32(0.6098433)), ('Close', np.float32(0.24146518)), ('BB_lower', np.float32(0.078155495))]\n",
      "\n",
      "NEAR - Close_t+7: Train=1211, Test=303\n",
      "   [RF best params] {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:34:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:34:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 1.0, 'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=1.304, MAE=0.962\n",
      "   XGB=> RMSE=1.263, MAE=0.926\n",
      "     Top RF feats: [('Close', np.float64(0.9453749436776713)), ('MA_20', np.float64(0.013987650902533368)), ('MACD_Signal', np.float64(0.009842564806066573))]\n",
      "     Top XGB feats: [('Close', np.float32(0.6449423)), ('BB_lower', np.float32(0.21688448)), ('BB_upper', np.float32(0.045883287))]\n",
      "\n",
      "NEAR - Close_t+30: Train=1211, Test=303\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:34:05] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:34:05] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 1.0, 'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=2.843, MAE=2.227\n",
      "   XGB=> RMSE=2.346, MAE=1.893\n",
      "     Top RF feats: [('Close', np.float64(0.7410021013902518)), ('MACD_Signal', np.float64(0.06140942963659215)), ('BB_lower', np.float64(0.05521059317538788))]\n",
      "     Top XGB feats: [('Close', np.float32(0.507954)), ('BB_lower', np.float32(0.22130114)), ('BB_upper', np.float32(0.06709925))]\n",
      "\n",
      "NEAR - Close_t+90: Train=1211, Test=303\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:34:09] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:34:09] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=4.937, MAE=3.494\n",
      "   XGB=> RMSE=5.110, MAE=3.769\n",
      "     Top RF feats: [('Close', np.float64(0.3560137159258099)), ('BB_upper', np.float64(0.19483801274786555)), ('BB_lower', np.float64(0.17392651501621845))]\n",
      "     Top XGB feats: [('Close', np.float32(0.27423188)), ('MA_20', np.float32(0.1747489)), ('BB_upper', np.float32(0.13770793))]\n",
      "\n",
      "\n",
      "=== Advanced Multi-Horizon (Optimized) for SHIB ===\n",
      "SHIB - Close_t+1: Train=1269, Test=318\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:34:12] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:34:12] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=0.000, MAE=0.000\n",
      "   XGB=> RMSE=0.000, MAE=0.000\n",
      "     Top RF feats: [('Close', np.float64(0.8811978841776518)), ('MA_20', np.float64(0.06717378346655928)), ('BB_upper', np.float64(0.027832783515028284))]\n",
      "     Top XGB feats: [('Close', np.float32(0.0)), ('MA_20', np.float32(0.0)), ('BB_upper', np.float32(0.0))]\n",
      "\n",
      "SHIB - Close_t+7: Train=1269, Test=318\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:34:15] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:34:15] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=0.000, MAE=0.000\n",
      "   XGB=> RMSE=0.000, MAE=0.000\n",
      "     Top RF feats: [('Close', np.float64(0.6935535388590862)), ('MA_20', np.float64(0.15227390371634156)), ('MACD_Signal', np.float64(0.12307937372142265))]\n",
      "     Top XGB feats: [('Close', np.float32(0.0)), ('MA_20', np.float32(0.0)), ('BB_upper', np.float32(0.0))]\n",
      "\n",
      "SHIB - Close_t+30: Train=1269, Test=318\n",
      "   [RF best params] {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:34:17] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:34:17] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=0.000, MAE=0.000\n",
      "   XGB=> RMSE=0.000, MAE=0.000\n",
      "     Top RF feats: [('Close', np.float64(0.5933277675827139)), ('MA_20', np.float64(0.1162404825698119)), ('BB_upper', np.float64(0.07229204378670469))]\n",
      "     Top XGB feats: [('Close', np.float32(0.0)), ('MA_20', np.float32(0.0)), ('BB_upper', np.float32(0.0))]\n",
      "\n",
      "SHIB - Close_t+90: Train=1269, Test=318\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:34:20] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:34:20] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=0.000, MAE=0.000\n",
      "   XGB=> RMSE=0.000, MAE=0.000\n",
      "     Top RF feats: [('MA_20', np.float64(0.6031828569706941)), ('BB_lower', np.float64(0.20978512547046904)), ('BB_upper', np.float64(0.10521944293784524))]\n",
      "     Top XGB feats: [('Close', np.float32(0.0)), ('MA_20', np.float32(0.0)), ('BB_upper', np.float32(0.0))]\n",
      "\n",
      "\n",
      "=== Advanced Multi-Horizon (Optimized) for SOL ===\n",
      "SOL - Close_t+1: Train=1360, Test=340\n",
      "   [RF best params] {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:34:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:34:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=7.953, MAE=6.189\n",
      "   XGB=> RMSE=9.634, MAE=7.605\n",
      "     Top RF feats: [('Close', np.float64(0.9972205140097378)), ('MACD', np.float64(0.0008672652743996446)), ('BB_upper', np.float64(0.0004415585566506247))]\n",
      "     Top XGB feats: [('Close', np.float32(0.5610261)), ('MA_20', np.float32(0.3365714)), ('BB_upper', np.float32(0.075401805))]\n",
      "\n",
      "SOL - Close_t+7: Train=1360, Test=340\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:34:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:34:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=21.917, MAE=17.495\n",
      "   XGB=> RMSE=25.305, MAE=21.130\n",
      "     Top RF feats: [('Close', np.float64(0.9524420129845513)), ('BB_upper', np.float64(0.011206166574167117)), ('MACD_Signal', np.float64(0.01107625922782793))]\n",
      "     Top XGB feats: [('Close', np.float32(0.5349162)), ('BB_upper', np.float32(0.3520618)), ('BB_lower', np.float32(0.036308))]\n",
      "\n",
      "SOL - Close_t+30: Train=1360, Test=340\n",
      "   [RF best params] {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:34:30] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:34:30] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=56.499, MAE=49.482\n",
      "   XGB=> RMSE=57.336, MAE=49.466\n",
      "     Top RF feats: [('Close', np.float64(0.7998614308955497)), ('BB_lower', np.float64(0.06403901574814112)), ('MACD_Signal', np.float64(0.051974274181211755))]\n",
      "     Top XGB feats: [('Close', np.float32(0.5158728)), ('BB_upper', np.float32(0.231555)), ('BB_lower', np.float32(0.055097803))]\n",
      "\n",
      "SOL - Close_t+90: Train=1360, Test=340\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:34:33] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:34:34] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=73.434, MAE=62.568\n",
      "   XGB=> RMSE=74.906, MAE=64.475\n",
      "     Top RF feats: [('BB_upper', np.float64(0.4105656385723402)), ('MACD', np.float64(0.13174119912462023)), ('MACD_Signal', np.float64(0.12659154473188158))]\n",
      "     Top XGB feats: [('BB_upper', np.float32(0.238543)), ('Close', np.float32(0.1352388)), ('MACD', np.float32(0.12579621))]\n",
      "\n",
      "\n",
      "=== Advanced Multi-Horizon (Optimized) for TON ===\n",
      "TON - Close_t+1: Train=957, Test=240\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:34:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:34:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=0.610, MAE=0.439\n",
      "   XGB=> RMSE=0.757, MAE=0.562\n",
      "     Top RF feats: [('Close', np.float64(0.9563164373293573)), ('MA_20', np.float64(0.02905160096789024)), ('Stoch_%K', np.float64(0.00291891572099719))]\n",
      "     Top XGB feats: [('Close', np.float32(0.40650785)), ('BB_upper', np.float32(0.26617566)), ('MACD', np.float32(0.13488227))]\n",
      "\n",
      "TON - Close_t+7: Train=957, Test=240\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:34:40] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:34:40] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=1.069, MAE=0.860\n",
      "   XGB=> RMSE=1.162, MAE=0.887\n",
      "     Top RF feats: [('Close', np.float64(0.8542001820481044)), ('MA_20', np.float64(0.04808842690908026)), ('BB_lower', np.float64(0.03684385043988931))]\n",
      "     Top XGB feats: [('Close', np.float32(0.46022496)), ('BB_upper', np.float32(0.1398986)), ('MACD_Signal', np.float32(0.1078648))]\n",
      "\n",
      "TON - Close_t+30: Train=957, Test=240\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:34:43] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:34:44] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=0.832, MAE=0.709\n",
      "   XGB=> RMSE=1.727, MAE=1.493\n",
      "     Top RF feats: [('Close', np.float64(0.5167489735012359)), ('BB_upper', np.float64(0.10646045573577045)), ('MA_20', np.float64(0.09538844571993102))]\n",
      "     Top XGB feats: [('Close', np.float32(0.35317272)), ('MACD_Signal', np.float32(0.19166857)), ('BB_lower', np.float32(0.09659297))]\n",
      "\n",
      "TON - Close_t+90: Train=957, Test=240\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:34:47] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:34:47] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 1.0, 'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=1.907, MAE=1.584\n",
      "   XGB=> RMSE=1.533, MAE=1.101\n",
      "     Top RF feats: [('Close', np.float64(0.390673966873435)), ('BB_lower', np.float64(0.16772194956706088)), ('MA_20', np.float64(0.12688547383091928))]\n",
      "     Top XGB feats: [('MACD_Hist', np.float32(0.20048098)), ('Close', np.float32(0.18301184)), ('BB_lower', np.float32(0.15537994))]\n",
      "\n",
      "\n",
      "=== Advanced Multi-Horizon (Optimized) for TRX ===\n",
      "TRX - Close_t+1: Train=2112, Test=528\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:34:52] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:34:52] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 1.0, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=0.030, MAE=0.012\n",
      "   XGB=> RMSE=0.037, MAE=0.017\n",
      "     Top RF feats: [('Close', np.float64(0.9862660027873464)), ('MA_20', np.float64(0.0059498314510767055)), ('BB_upper', np.float64(0.002202693127731504))]\n",
      "     Top XGB feats: [('BB_upper', np.float32(0.61628133)), ('Close', np.float32(0.32145885)), ('MA_20', np.float32(0.027283013))]\n",
      "\n",
      "TRX - Close_t+7: Train=2112, Test=528\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:34:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:34:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=0.056, MAE=0.036\n",
      "   XGB=> RMSE=0.055, MAE=0.036\n",
      "     Top RF feats: [('BB_upper', np.float64(0.6057369482484248)), ('Close', np.float64(0.3249154146475997)), ('MA_20', np.float64(0.021893051932786713))]\n",
      "     Top XGB feats: [('BB_upper', np.float32(0.61801445)), ('Close', np.float32(0.19489957)), ('MACD_Signal', np.float32(0.04704894))]\n",
      "\n",
      "TRX - Close_t+30: Train=2112, Test=528\n",
      "   [RF best params] {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:35:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:35:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=0.073, MAE=0.054\n",
      "   XGB=> RMSE=0.075, MAE=0.055\n",
      "     Top RF feats: [('BB_upper', np.float64(0.6153960959350466)), ('Close', np.float64(0.1540577474514752)), ('BB_lower', np.float64(0.13702505827819042))]\n",
      "     Top XGB feats: [('BB_upper', np.float32(0.56933564)), ('Close', np.float32(0.13423565)), ('BB_lower', np.float32(0.051163185))]\n",
      "\n",
      "TRX - Close_t+90: Train=2112, Test=528\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:35:08] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:35:08] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=0.103, MAE=0.086\n",
      "   XGB=> RMSE=0.102, MAE=0.085\n",
      "     Top RF feats: [('Close', np.float64(0.31219811781488416)), ('MA_20', np.float64(0.26907879409935065)), ('BB_upper', np.float64(0.1552517183618936))]\n",
      "     Top XGB feats: [('Close', np.float32(0.26445717)), ('BB_upper', np.float32(0.21799883)), ('MA_20', np.float32(0.18509562))]\n",
      "\n",
      "\n",
      "=== Advanced Multi-Horizon (Optimized) for UNI ===\n",
      "UNI - Close_t+1: Train=1232, Test=308\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:35:12] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:35:12] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=0.784, MAE=0.539\n",
      "   XGB=> RMSE=0.712, MAE=0.482\n",
      "     Top RF feats: [('Close', np.float64(0.9925291127301175)), ('MACD', np.float64(0.0011094157086408527)), ('MA_20', np.float64(0.001026623367504813))]\n",
      "     Top XGB feats: [('BB_upper', np.float32(0.5821045)), ('Close', np.float32(0.35073662)), ('MA_20', np.float32(0.02415942))]\n",
      "\n",
      "UNI - Close_t+7: Train=1232, Test=308\n",
      "   [RF best params] {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:35:16] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:35:16] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=2.089, MAE=1.464\n",
      "   XGB=> RMSE=1.643, MAE=1.160\n",
      "     Top RF feats: [('Close', np.float64(0.7744738575473776)), ('BB_upper', np.float64(0.1462297502916088)), ('MACD_Signal', np.float64(0.018419469775907787))]\n",
      "     Top XGB feats: [('BB_upper', np.float32(0.48782456)), ('Close', np.float32(0.31614888)), ('MA_20', np.float32(0.07646549))]\n",
      "\n",
      "UNI - Close_t+30: Train=1232, Test=308\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:35:21] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:35:21] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=5.033, MAE=3.414\n",
      "   XGB=> RMSE=3.756, MAE=2.589\n",
      "     Top RF feats: [('BB_upper', np.float64(0.7696837899834953)), ('MACD', np.float64(0.07485275087067432)), ('MACD_Signal', np.float64(0.053863840456541495))]\n",
      "     Top XGB feats: [('BB_upper', np.float32(0.58057)), ('Close', np.float32(0.1481357)), ('MACD', np.float32(0.09890657))]\n",
      "\n",
      "UNI - Close_t+90: Train=1232, Test=308\n",
      "   [RF best params] {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:35:24] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:35:24] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 1.0, 'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=9.558, MAE=6.089\n",
      "   XGB=> RMSE=9.065, MAE=5.921\n",
      "     Top RF feats: [('Close', np.float64(0.3029549195126955)), ('BB_lower', np.float64(0.28099566129343717)), ('MACD_Signal', np.float64(0.11824218674317648))]\n",
      "     Top XGB feats: [('Close', np.float32(0.3057158)), ('BB_lower', np.float32(0.1909681)), ('BB_upper', np.float32(0.13001172))]\n",
      "\n",
      "\n",
      "=== Advanced Multi-Horizon (Optimized) for XRP ===\n",
      "XRP - Close_t+1: Train=3312, Test=829\n",
      "   [RF best params] {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:35:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:35:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=0.071, MAE=0.031\n",
      "   XGB=> RMSE=0.094, MAE=0.036\n",
      "     Top RF feats: [('Close', np.float64(0.9499397889810682)), ('MACD', np.float64(0.016730753111059503)), ('MACD_Hist', np.float64(0.013994224830386091))]\n",
      "     Top XGB feats: [('BB_upper', np.float32(0.45479828)), ('Close', np.float32(0.33327198)), ('MACD_Signal', np.float32(0.07767707))]\n",
      "\n",
      "XRP - Close_t+7: Train=3312, Test=829\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:35:46] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:35:46] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=0.199, MAE=0.104\n",
      "   XGB=> RMSE=0.183, MAE=0.084\n",
      "     Top RF feats: [('Close', np.float64(0.7883632354339881)), ('MACD_Signal', np.float64(0.07706385099560498)), ('MA_20', np.float64(0.03599042078077766))]\n",
      "     Top XGB feats: [('BB_upper', np.float32(0.46669948)), ('Close', np.float32(0.28166455)), ('MACD_Signal', np.float32(0.09395599))]\n",
      "\n",
      "XRP - Close_t+30: Train=3312, Test=829\n",
      "   [RF best params] {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:35:53] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:35:53] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [XGB best params] {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=0.434, MAE=0.206\n",
      "   XGB=> RMSE=0.442, MAE=0.206\n",
      "     Top RF feats: [('Close', np.float64(0.7689219090236894)), ('MA_20', np.float64(0.08865914365539748)), ('BB_upper', np.float64(0.07943166986396151))]\n",
      "     Top XGB feats: [('Close', np.float32(0.36180595)), ('BB_upper', np.float32(0.19902249)), ('Stoch_%K', np.float32(0.14051919))]\n",
      "\n",
      "XRP - Close_t+90: Train=3312, Test=829\n",
      "   [RF best params] {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 5}\n",
      "   [XGB best params] {'subsample': 1.0, 'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "   RF => RMSE=0.759, MAE=0.373\n",
      "   XGB=> RMSE=0.749, MAE=0.373\n",
      "     Top RF feats: [('BB_upper', np.float64(0.46655871533033305)), ('MA_20', np.float64(0.3039919793745543)), ('MACD_Hist', np.float64(0.0696250716493035))]\n",
      "     Top XGB feats: [('BB_upper', np.float32(0.28969738)), ('MA_20', np.float32(0.1824291)), ('BB_lower', np.float32(0.09482774))]\n",
      "\n",
      "\n",
      "=== Saved advanced multi-horizon results to: ../data\\advanced_ratio_multihorizon_results_optimized.csv ===\n",
      "    Coin     Horizon       RF_RMSE        RF_MAE      XGB_RMSE       XGB_MAE\n",
      "0    ADA   Close_t+1      0.025445      0.016708      0.028275      0.018721\n",
      "1    ADA   Close_t+7      0.070317      0.048611      0.076173      0.052353\n",
      "2    ADA  Close_t+30      0.199159      0.127662      0.203981      0.125602\n",
      "3    ADA  Close_t+90      0.324284      0.217756      0.316206      0.209011\n",
      "4   AVAX   Close_t+1      2.337897      1.626471      2.633515      1.840575\n",
      "5   AVAX   Close_t+7      6.405296      4.671014      6.516587      4.870371\n",
      "6   AVAX  Close_t+30     13.767214     10.297995     13.147630      9.960141\n",
      "7   AVAX  Close_t+90     25.241952     22.064108     26.568110     21.474070\n",
      "8    BCH   Close_t+1     19.518295     12.755353     19.133087     12.330786\n",
      "9    BCH   Close_t+7     49.220721     35.098500     49.544626     32.602816\n",
      "10   BCH  Close_t+30    101.694522     73.490258     86.247121     60.785779\n",
      "11   BCH  Close_t+90    262.559334    180.404877    243.643506    163.855384\n",
      "12   BNB   Close_t+1     28.021811     17.768952     36.483627     23.102802\n",
      "13   BNB   Close_t+7     96.993655     60.002880     65.989992     46.168318\n",
      "14   BNB  Close_t+30    121.536073    100.739636    116.616001     98.340332\n",
      "15   BNB  Close_t+90    199.940286    174.566718    198.963942    174.262128\n",
      "16   BTC   Close_t+1   7386.967207   3532.142089   7557.049216   3700.352238\n",
      "17   BTC   Close_t+7  11818.634941   8935.650945  10770.625642   7778.203816\n",
      "18   BTC  Close_t+30  18585.162594  15604.170734  19051.825121  15744.287903\n",
      "19   BTC  Close_t+90  31147.444943  28158.079955  31081.836708  28051.561308\n",
      "20  DOGE   Close_t+1      0.017629      0.008519      0.016633      0.009730\n",
      "21  DOGE   Close_t+7      0.041519      0.025003      0.035785      0.021859\n",
      "22  DOGE  Close_t+30      0.080432      0.048503      0.076161      0.044252\n",
      "23  DOGE  Close_t+90      0.106775      0.061322      0.106922      0.061793\n",
      "24   DOT   Close_t+1      0.371437      0.257835      0.484433      0.286401\n",
      "25   DOT   Close_t+7      1.643077      1.009809      1.493748      0.980484\n",
      "26   DOT  Close_t+30      4.340223      2.248620      4.170168      2.269771\n",
      "27   DOT  Close_t+90      9.316324      5.374049      8.662280      4.916107\n",
      "28   ETH   Close_t+1    114.695488     74.892581    109.377821     78.308911\n",
      "29   ETH   Close_t+7    267.933617    196.371497    298.829880    217.891946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:36:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\lukeb\\crypto-forecasting-capstone\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:36:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# 05_multihorizon_advanced_ratio_optimized.ipynb\n",
    "# ---------------------------------------------------------\n",
    "# PURPOSE:\n",
    "#   1) Perform a multi-horizon forecast (Close_t+1, t+7, t+30, t+90).\n",
    "#   2) Use advanced ML (RandomForest, XGBRegressor).\n",
    "#   3) Add hyperparameter tuning with RandomizedSearchCV.\n",
    "#   4) Use TimeSeriesSplit for more chronologically-aware CV.\n",
    "#   5) Evaluate RMSE & MAE on test sets for each horizon.\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Sklearn Regressors and Tools\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# XGBoost (check availability)\n",
    "try:\n",
    "    from xgboost import XGBRegressor\n",
    "    xgb_available = True\n",
    "except ImportError:\n",
    "    xgb_available = False\n",
    "\n",
    "sns.set_theme(font_scale=1.1)\n",
    "\n",
    "DATA_FOLDER = \"../data\"\n",
    "\n",
    "# Example coin list\n",
    "all_coins = [\n",
    "    \"ADA\", \"AVAX\", \"BCH\", \"BNB\", \"BTC\",\n",
    "    \"DOGE\", \"DOT\", \"ETH\", \"LEO\", \"LINK\",\n",
    "    \"LTC\", \"MATIC\", \"NEAR\", \"SHIB\", \"SOL\",\n",
    "    \"TON\", \"TRX\", \"UNI\", \"XRP\"\n",
    "]\n",
    "\n",
    "# Horizons\n",
    "horizons = [\"Close_t+1\", \"Close_t+7\", \"Close_t+30\", \"Close_t+90\"]\n",
    "\n",
    "# Feature columns from your feature engineering\n",
    "feature_cols = [\n",
    "    \"Close\",\"MA_20\",\"BB_upper\",\"BB_lower\",\"RSI_14\",\n",
    "    \"MACD\",\"MACD_Signal\",\"MACD_Hist\",\n",
    "    \"Stoch_%K\",\"Stoch_%D\"\n",
    "]\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def mae(y_true, y_pred):\n",
    "    return mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "results = []\n",
    "\n",
    "# Predefine small parameter distributions for random search\n",
    "# You can expand these if you want a deeper search.\n",
    "rf_param_dist = {\n",
    "    \"n_estimators\": [100, 200],\n",
    "    \"max_depth\": [3, 5, 7, None],\n",
    "    \"min_samples_split\": [2, 5],\n",
    "    \"min_samples_leaf\": [1, 2],\n",
    "}\n",
    "\n",
    "if xgb_available:\n",
    "    xgb_param_dist = {\n",
    "        \"n_estimators\": [100, 200],\n",
    "        \"max_depth\": [3, 5, 7],\n",
    "        \"learning_rate\": [0.1, 0.05],\n",
    "        \"subsample\": [1.0, 0.8],\n",
    "        \"colsample_bytree\": [1.0, 0.8],\n",
    "    }\n",
    "\n",
    "# We'll use a small TimeSeriesSplit for hyperparameter search\n",
    "# (You can adjust n_splits for more robust search)\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "for coin in all_coins:\n",
    "    print(f\"\\n=== Advanced Multi-Horizon (Optimized) for {coin} ===\")\n",
    "\n",
    "    # 1) Load the train/test CSVs from your previous notebooks\n",
    "    train_csv = f\"{coin.lower()}_train_multi.csv\"\n",
    "    test_csv  = f\"{coin.lower()}_test_multi.csv\"\n",
    "    train_path = os.path.join(DATA_FOLDER, train_csv)\n",
    "    test_path  = os.path.join(DATA_FOLDER, test_csv)\n",
    "\n",
    "    if not (os.path.exists(train_path) and os.path.exists(test_path)):\n",
    "        print(f\"[{coin}] Missing train/test CSV, skipping...\")\n",
    "        continue\n",
    "\n",
    "    train_df = pd.read_csv(train_path, parse_dates=[\"Date\"])\n",
    "    test_df  = pd.read_csv(test_path,  parse_dates=[\"Date\"])\n",
    "\n",
    "    if len(train_df) < 20:\n",
    "        print(f\"[{coin}] Train set <20 rows, skipping coin.\")\n",
    "        continue\n",
    "    if len(test_df) == 0:\n",
    "        print(f\"[{coin}] Test set empty, skipping coin.\")\n",
    "        continue\n",
    "\n",
    "    # For each horizon\n",
    "    for horizon_col in horizons:\n",
    "        if horizon_col not in train_df.columns:\n",
    "            continue\n",
    "\n",
    "        # Local copies to handle dropna per horizon\n",
    "        train_local = train_df.copy()\n",
    "        test_local  = test_df.copy()\n",
    "\n",
    "        # Drop rows missing features or horizon\n",
    "        train_local.dropna(subset=feature_cols + [horizon_col], inplace=True)\n",
    "        test_local.dropna(subset=feature_cols + [horizon_col], inplace=True)\n",
    "\n",
    "        # If no data left\n",
    "        if len(train_local) < 10 or len(test_local) < 1:\n",
    "            print(f\"{coin} - {horizon_col}: not enough data after dropna, skipping horizon.\")\n",
    "            continue\n",
    "\n",
    "        X_train = train_local[feature_cols]\n",
    "        y_train = train_local[horizon_col]\n",
    "        X_test  = test_local[feature_cols]\n",
    "        y_test  = test_local[horizon_col]\n",
    "\n",
    "        print(f\"{coin} - {horizon_col}: Train={len(X_train)}, Test={len(X_test)}\")\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        #  Hyperparameter Tuning for RANDOM FOREST\n",
    "        # -------------------------------------------------\n",
    "        rf_base = RandomForestRegressor(random_state=42)\n",
    "        rf_search = RandomizedSearchCV(\n",
    "            estimator=rf_base,\n",
    "            param_distributions=rf_param_dist,\n",
    "            n_iter=6,  # number of random combos\n",
    "            scoring=\"neg_mean_squared_error\",  # or \"neg_mean_absolute_error\"\n",
    "            cv=tscv,   # time series split\n",
    "            n_jobs=-1, # use all cores\n",
    "            random_state=42,\n",
    "            verbose=0\n",
    "        )\n",
    "        # Fit the random search\n",
    "        rf_search.fit(X_train, y_train)\n",
    "        best_rf = rf_search.best_estimator_\n",
    "        # Log the best params\n",
    "        print(f\"   [RF best params] {rf_search.best_params_}\")\n",
    "\n",
    "        # Fit final best RF on the entire train set\n",
    "        best_rf.fit(X_train, y_train)\n",
    "        rf_pred = best_rf.predict(X_test)\n",
    "        rf_rmse_val = rmse(y_test, rf_pred)\n",
    "        rf_mae_val  = mae(y_test, rf_pred)\n",
    "\n",
    "        # Feature importances (Top 3)\n",
    "        rf_importances = best_rf.feature_importances_\n",
    "        top_feats_rf = sorted(zip(feature_cols, rf_importances), key=lambda x: x[1], reverse=True)[:3]\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        #  Hyperparameter Tuning for XGBOOST (if available)\n",
    "        # -------------------------------------------------\n",
    "        xgb_rmse_val, xgb_mae_val = np.nan, np.nan\n",
    "        xgb_best_params = None\n",
    "\n",
    "        if xgb_available:\n",
    "            xgb_base = XGBRegressor(random_state=42, use_label_encoder=False, eval_metric=\"rmse\")\n",
    "            xgb_search = RandomizedSearchCV(\n",
    "                estimator=xgb_base,\n",
    "                param_distributions=xgb_param_dist,\n",
    "                n_iter=6,  # random combos\n",
    "                scoring=\"neg_mean_squared_error\",\n",
    "                cv=tscv,\n",
    "                n_jobs=-1,\n",
    "                random_state=42,\n",
    "                verbose=0\n",
    "            )\n",
    "            xgb_search.fit(X_train, y_train)\n",
    "            best_xgb = xgb_search.best_estimator_\n",
    "            xgb_best_params = xgb_search.best_params_\n",
    "            print(f\"   [XGB best params] {xgb_best_params}\")\n",
    "\n",
    "            # Fit final best XGB\n",
    "            best_xgb.fit(X_train, y_train)\n",
    "            xgb_pred = best_xgb.predict(X_test)\n",
    "\n",
    "            xgb_rmse_val = rmse(y_test, xgb_pred)\n",
    "            xgb_mae_val  = mae(y_test, xgb_pred)\n",
    "\n",
    "            # (Optional) XGB feature importances\n",
    "            xgb_importances = best_xgb.feature_importances_\n",
    "            top_feats_xgb = sorted(zip(feature_cols, xgb_importances), key=lambda x: x[1], reverse=True)[:3]\n",
    "        else:\n",
    "            print(\"   [XGBoost not installed, skipping XGB model]\")\n",
    "\n",
    "        # Print final metrics\n",
    "        print(f\"   RF => RMSE={rf_rmse_val:.3f}, MAE={rf_mae_val:.3f}\")\n",
    "        if xgb_available:\n",
    "            print(f\"   XGB=> RMSE={xgb_rmse_val:.3f}, MAE={xgb_mae_val:.3f}\")\n",
    "\n",
    "        print(f\"     Top RF feats: {top_feats_rf}\")\n",
    "        if xgb_available:\n",
    "            print(f\"     Top XGB feats: {top_feats_xgb}\\n\")\n",
    "\n",
    "        results.append({\n",
    "            \"Coin\": coin,\n",
    "            \"Horizon\": horizon_col,\n",
    "            \"RF_RMSE\": rf_rmse_val,\n",
    "            \"RF_MAE\": rf_mae_val,\n",
    "            \"XGB_RMSE\": xgb_rmse_val,\n",
    "            \"XGB_MAE\": xgb_mae_val\n",
    "        })\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Convert results to DataFrame and Save\n",
    "# ---------------------------------------------------------\n",
    "results_df = pd.DataFrame(results)\n",
    "out_csv = os.path.join(DATA_FOLDER, \"advanced_ratio_multihorizon_results_optimized.csv\")\n",
    "results_df.to_csv(out_csv, index=False)\n",
    "print(f\"\\n=== Saved advanced multi-horizon results to: {out_csv} ===\")\n",
    "print(results_df.head(30))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
